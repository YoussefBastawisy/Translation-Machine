{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1067156,"sourceType":"datasetVersion","datasetId":592212}],"dockerImageVersionId":30615,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# basic libs\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# cleaning data\nimport re\nimport os\nimport nltk\nnltk.download(\"stopwords\")\nnltk.download('punkt')\n\n# save vocabulary in files\nimport pickle\n\n# tokenization\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\n# Model\nfrom tensorflow.keras.layers import LSTM,Embedding,Input,Dense,SpatialDropout1D,Activation , Conv1D , GlobalMaxPooling1D\nfrom keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Concatenate , Flatten ,Reshape\nfrom keras.optimizers import Adam\nfrom tensorflow.keras.models import Model,Sequential\n\n# training model dependanices\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.utils import to_categorical","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-01T09:43:05.901645Z","iopub.execute_input":"2024-01-01T09:43:05.901917Z","iopub.status.idle":"2024-01-01T09:43:27.032213Z","shell.execute_reply.started":"2024-01-01T09:43:05.901892Z","shell.execute_reply":"2024-01-01T09:43:27.031393Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/language-translation-englishfrench/eng_-french.csv\")\ndf.columns=[\"english\",\"frensh\"]\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-01T09:43:27.033820Z","iopub.execute_input":"2024-01-01T09:43:27.034383Z","iopub.status.idle":"2024-01-01T09:43:27.584789Z","shell.execute_reply.started":"2024-01-01T09:43:27.034357Z","shell.execute_reply":"2024-01-01T09:43:27.583826Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"  english      frensh\n0     Hi.      Salut!\n1    Run!     Cours !\n2    Run!    Courez !\n3    Who?       Qui ?\n4    Wow!  Ça alors !","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>english</th>\n      <th>frensh</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Hi.</td>\n      <td>Salut!</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Run!</td>\n      <td>Cours !</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Run!</td>\n      <td>Courez !</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Who?</td>\n      <td>Qui ?</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Wow!</td>\n      <td>Ça alors !</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2024-01-01T09:43:27.586048Z","iopub.execute_input":"2024-01-01T09:43:27.586423Z","iopub.status.idle":"2024-01-01T09:43:27.647107Z","shell.execute_reply.started":"2024-01-01T09:43:27.586389Z","shell.execute_reply":"2024-01-01T09:43:27.646082Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 175621 entries, 0 to 175620\nData columns (total 2 columns):\n #   Column   Non-Null Count   Dtype \n---  ------   --------------   ----- \n 0   english  175621 non-null  object\n 1   frensh   175621 non-null  object\ndtypes: object(2)\nmemory usage: 2.7+ MB\n","output_type":"stream"}]},{"cell_type":"code","source":"data=df[:]\ndata.info()","metadata":{"execution":{"iopub.status.busy":"2024-01-01T09:43:27.649942Z","iopub.execute_input":"2024-01-01T09:43:27.650322Z","iopub.status.idle":"2024-01-01T09:43:27.690664Z","shell.execute_reply.started":"2024-01-01T09:43:27.650288Z","shell.execute_reply":"2024-01-01T09:43:27.689706Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 175621 entries, 0 to 175620\nData columns (total 2 columns):\n #   Column   Non-Null Count   Dtype \n---  ------   --------------   ----- \n 0   english  175621 non-null  object\n 1   frensh   175621 non-null  object\ndtypes: object(2)\nmemory usage: 2.7+ MB\n","output_type":"stream"}]},{"cell_type":"code","source":"# clean english column\ndef clean_english(text):\n  text=text.lower() # lower case\n\n  # remove any characters not a-z and ?!,'\n  text=re.sub(u\"[^a-z!?',]\",\" \",text)\n\n  # word tokenization\n  text=nltk.word_tokenize(text)\n\n  # join text\n  text=\" \".join([i.strip() for i in text])\n\n  return text\nclean_english(data.iloc[0,0])","metadata":{"execution":{"iopub.status.busy":"2024-01-01T09:43:27.691844Z","iopub.execute_input":"2024-01-01T09:43:27.692167Z","iopub.status.idle":"2024-01-01T09:43:27.718160Z","shell.execute_reply.started":"2024-01-01T09:43:27.692137Z","shell.execute_reply":"2024-01-01T09:43:27.717339Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"'hi'"},"metadata":{}}]},{"cell_type":"code","source":"data.iloc[1,0],clean_english(data.iloc[1,0])","metadata":{"execution":{"iopub.status.busy":"2024-01-01T09:43:27.719304Z","iopub.execute_input":"2024-01-01T09:43:27.719604Z","iopub.status.idle":"2024-01-01T09:43:27.726755Z","shell.execute_reply.started":"2024-01-01T09:43:27.719576Z","shell.execute_reply":"2024-01-01T09:43:27.725761Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"('Run!', 'run !')"},"metadata":{}}]},{"cell_type":"code","source":"# clean frensh language\ndef clean_frensh(text):\n  text=text.lower() # lower case\n\n  # remove any characters not a-z and ?!,'\n  # characters a-z and (éâàçêêëôîû) chars of frensh lang which contain accent\n  text=re.sub(u\"[^a-zéâàçêêëôîû!?',]\",\" \",text)\n\n  return text\nclean_frensh(data.iloc[0,1])","metadata":{"execution":{"iopub.status.busy":"2024-01-01T09:43:27.728113Z","iopub.execute_input":"2024-01-01T09:43:27.728418Z","iopub.status.idle":"2024-01-01T09:43:27.737522Z","shell.execute_reply.started":"2024-01-01T09:43:27.728389Z","shell.execute_reply":"2024-01-01T09:43:27.736718Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"'salut!'"},"metadata":{}}]},{"cell_type":"code","source":"data.iloc[4,1],clean_frensh(data.iloc[4,1])","metadata":{"execution":{"iopub.status.busy":"2024-01-01T09:43:27.738750Z","iopub.execute_input":"2024-01-01T09:43:27.739065Z","iopub.status.idle":"2024-01-01T09:43:27.748291Z","shell.execute_reply.started":"2024-01-01T09:43:27.739037Z","shell.execute_reply":"2024-01-01T09:43:27.747426Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"('Ça alors\\u202f!', 'ça alors !')"},"metadata":{}}]},{"cell_type":"code","source":"# i show this two functions are ready to apply in dataframe\ndata[\"english\"]=data[\"english\"].apply(lambda txt:clean_english(txt))\ndata[\"frensh\"]=data[\"frensh\"].apply(lambda txt:clean_frensh(txt))","metadata":{"execution":{"iopub.status.busy":"2024-01-01T09:43:27.749433Z","iopub.execute_input":"2024-01-01T09:43:27.749761Z","iopub.status.idle":"2024-01-01T09:43:50.848407Z","shell.execute_reply.started":"2024-01-01T09:43:27.749734Z","shell.execute_reply":"2024-01-01T09:43:50.847431Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# add <start> <end> token to decoder sentence (Frensh)\ndata[\"frensh\"]=data[\"frensh\"].apply(lambda txt:f\"<start> {txt} <end>\")","metadata":{"execution":{"iopub.status.busy":"2024-01-01T09:43:50.852029Z","iopub.execute_input":"2024-01-01T09:43:50.852339Z","iopub.status.idle":"2024-01-01T09:43:50.939765Z","shell.execute_reply.started":"2024-01-01T09:43:50.852312Z","shell.execute_reply":"2024-01-01T09:43:50.939024Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"data.sample(10)","metadata":{"execution":{"iopub.status.busy":"2024-01-01T09:43:50.940797Z","iopub.execute_input":"2024-01-01T09:43:50.941088Z","iopub.status.idle":"2024-01-01T09:43:50.956858Z","shell.execute_reply.started":"2024-01-01T09:43:50.941064Z","shell.execute_reply":"2024-01-01T09:43:50.955823Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                                                  english  \\\n93756                     what 've you been doing today ?   \n60488                            his dog is barking at me   \n74752                          he has been gaining weight   \n79840                        what happened at the beach ?   \n24671                                 i 'm letting you go   \n27474                                 you 'll bounce back   \n99340                       this problem is not avoidable   \n163562  she raised an important objection to his argument   \n170601  you should get yourself examined by the doctor...   \n119757                 i do n't know if i should tell you   \n\n                                                   frensh  \n93756       <start> qu'avez vous fait aujourd'hui ? <end>  \n60488             <start> son chien m'aboie dessus  <end>  \n74752                   <start> il a pris du poids  <end>  \n79840       <start> que s'est il passé à la plage ? <end>  \n24671                         <start> je te lib re  <end>  \n27474               <start> vous vous en remettrez  <end>  \n99340           <start> ce probl me est inévitable  <end>  \n163562  <start> elle souleva une objection importante ...  \n170601  <start> tu devrais immédiatement aller te fair...  \n119757  <start> c'est moi qui ignore si je devrais te ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>english</th>\n      <th>frensh</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>93756</th>\n      <td>what 've you been doing today ?</td>\n      <td>&lt;start&gt; qu'avez vous fait aujourd'hui ? &lt;end&gt;</td>\n    </tr>\n    <tr>\n      <th>60488</th>\n      <td>his dog is barking at me</td>\n      <td>&lt;start&gt; son chien m'aboie dessus  &lt;end&gt;</td>\n    </tr>\n    <tr>\n      <th>74752</th>\n      <td>he has been gaining weight</td>\n      <td>&lt;start&gt; il a pris du poids  &lt;end&gt;</td>\n    </tr>\n    <tr>\n      <th>79840</th>\n      <td>what happened at the beach ?</td>\n      <td>&lt;start&gt; que s'est il passé à la plage ? &lt;end&gt;</td>\n    </tr>\n    <tr>\n      <th>24671</th>\n      <td>i 'm letting you go</td>\n      <td>&lt;start&gt; je te lib re  &lt;end&gt;</td>\n    </tr>\n    <tr>\n      <th>27474</th>\n      <td>you 'll bounce back</td>\n      <td>&lt;start&gt; vous vous en remettrez  &lt;end&gt;</td>\n    </tr>\n    <tr>\n      <th>99340</th>\n      <td>this problem is not avoidable</td>\n      <td>&lt;start&gt; ce probl me est inévitable  &lt;end&gt;</td>\n    </tr>\n    <tr>\n      <th>163562</th>\n      <td>she raised an important objection to his argument</td>\n      <td>&lt;start&gt; elle souleva une objection importante ...</td>\n    </tr>\n    <tr>\n      <th>170601</th>\n      <td>you should get yourself examined by the doctor...</td>\n      <td>&lt;start&gt; tu devrais immédiatement aller te fair...</td>\n    </tr>\n    <tr>\n      <th>119757</th>\n      <td>i do n't know if i should tell you</td>\n      <td>&lt;start&gt; c'est moi qui ignore si je devrais te ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# english tokenizer\nenglish_tokenize=Tokenizer(filters='#$%&()*+,-./:;<=>@[\\\\]^_`{|}~\\t\\n')\nenglish_tokenize.fit_on_texts(data[\"english\"])","metadata":{"execution":{"iopub.status.busy":"2024-01-01T09:43:50.958102Z","iopub.execute_input":"2024-01-01T09:43:50.958988Z","iopub.status.idle":"2024-01-01T09:43:53.315174Z","shell.execute_reply.started":"2024-01-01T09:43:50.958950Z","shell.execute_reply":"2024-01-01T09:43:53.314407Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"num_encoder_tokens=len(english_tokenize.word_index)\nnum_encoder_tokens","metadata":{"execution":{"iopub.status.busy":"2024-01-01T09:43:53.316481Z","iopub.execute_input":"2024-01-01T09:43:53.317031Z","iopub.status.idle":"2024-01-01T09:43:53.322940Z","shell.execute_reply.started":"2024-01-01T09:43:53.316981Z","shell.execute_reply":"2024-01-01T09:43:53.322086Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"13904"},"metadata":{}}]},{"cell_type":"code","source":"encoder=english_tokenize.texts_to_sequences(data[\"english\"])\nencoder[:5]","metadata":{"execution":{"iopub.status.busy":"2024-01-01T09:43:53.324268Z","iopub.execute_input":"2024-01-01T09:43:53.325154Z","iopub.status.idle":"2024-01-01T09:43:55.474506Z","shell.execute_reply.started":"2024-01-01T09:43:53.325121Z","shell.execute_reply":"2024-01-01T09:43:55.473555Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"[[2745], [408, 124], [408, 124], [77, 5], [3483, 124]]"},"metadata":{}}]},{"cell_type":"code","source":"max_encoder_sequence_len=np.max([len(enc) for enc in encoder])\nmax_encoder_sequence_len","metadata":{"execution":{"iopub.status.busy":"2024-01-01T09:43:55.475652Z","iopub.execute_input":"2024-01-01T09:43:55.475935Z","iopub.status.idle":"2024-01-01T09:43:55.512888Z","shell.execute_reply.started":"2024-01-01T09:43:55.475910Z","shell.execute_reply":"2024-01-01T09:43:55.512008Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"47"},"metadata":{}}]},{"cell_type":"code","source":"# frensh tokenizer\nfrench_tokenize=Tokenizer(filters=\"#$%&()*+,-./:;<=>@[\\\\]^_`{|}~\\t\\n\")\nfrench_tokenize.fit_on_texts(data[\"frensh\"])","metadata":{"execution":{"iopub.status.busy":"2024-01-01T09:43:55.513972Z","iopub.execute_input":"2024-01-01T09:43:55.514331Z","iopub.status.idle":"2024-01-01T09:43:58.709109Z","shell.execute_reply.started":"2024-01-01T09:43:55.514303Z","shell.execute_reply":"2024-01-01T09:43:58.708111Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"num_decoder_tokens=len(french_tokenize.word_index)\nnum_decoder_tokens","metadata":{"execution":{"iopub.status.busy":"2024-01-01T09:43:58.710502Z","iopub.execute_input":"2024-01-01T09:43:58.710912Z","iopub.status.idle":"2024-01-01T09:43:58.717835Z","shell.execute_reply.started":"2024-01-01T09:43:58.710875Z","shell.execute_reply":"2024-01-01T09:43:58.716875Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"26942"},"metadata":{}}]},{"cell_type":"code","source":"decoder=french_tokenize.texts_to_sequences(data[\"frensh\"])\ndecoder[:5]","metadata":{"execution":{"iopub.status.busy":"2024-01-01T09:43:58.719284Z","iopub.execute_input":"2024-01-01T09:43:58.719874Z","iopub.status.idle":"2024-01-01T09:44:01.545730Z","shell.execute_reply.started":"2024-01-01T09:43:58.719840Z","shell.execute_reply":"2024-01-01T09:44:01.544818Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"[[2, 16889, 1],\n [2, 572, 33, 1],\n [2, 5116, 33, 1],\n [2, 39, 6, 1],\n [2, 32, 393, 33, 1]]"},"metadata":{}}]},{"cell_type":"code","source":"max_decoder_sequence_len=np.max([len(dec) for dec in decoder])\nmax_decoder_sequence_len","metadata":{"execution":{"iopub.status.busy":"2024-01-01T09:44:01.546827Z","iopub.execute_input":"2024-01-01T09:44:01.547154Z","iopub.status.idle":"2024-01-01T09:44:01.585414Z","shell.execute_reply.started":"2024-01-01T09:44:01.547128Z","shell.execute_reply":"2024-01-01T09:44:01.584467Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"57"},"metadata":{}}]},{"cell_type":"code","source":"idx_2_txt_decoder={k:i for i,k in french_tokenize.word_index.items()}\nidx_2_txt_decoder[1]","metadata":{"execution":{"iopub.status.busy":"2024-01-01T09:44:01.586750Z","iopub.execute_input":"2024-01-01T09:44:01.587111Z","iopub.status.idle":"2024-01-01T09:44:01.599571Z","shell.execute_reply.started":"2024-01-01T09:44:01.587044Z","shell.execute_reply":"2024-01-01T09:44:01.598638Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"'end'"},"metadata":{}}]},{"cell_type":"code","source":"idx_2_txt_encoder={k:i for i,k in english_tokenize.word_index.items()}\nidx_2_txt_encoder[2]","metadata":{"execution":{"iopub.status.busy":"2024-01-01T09:44:01.600857Z","iopub.execute_input":"2024-01-01T09:44:01.601511Z","iopub.status.idle":"2024-01-01T09:44:01.614263Z","shell.execute_reply.started":"2024-01-01T09:44:01.601480Z","shell.execute_reply":"2024-01-01T09:44:01.613321Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"'you'"},"metadata":{}}]},{"cell_type":"code","source":"idx_2_txt_decoder[0]=\"<pad>\"\nidx_2_txt_encoder[0]=\"<pad>\"","metadata":{"execution":{"iopub.status.busy":"2024-01-01T09:44:01.615355Z","iopub.execute_input":"2024-01-01T09:44:01.616146Z","iopub.status.idle":"2024-01-01T09:44:01.624748Z","shell.execute_reply.started":"2024-01-01T09:44:01.616121Z","shell.execute_reply":"2024-01-01T09:44:01.624066Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"encoder_seq=pad_sequences(encoder,maxlen=max_encoder_sequence_len,padding=\"post\")\nencoder_seq.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-01T09:44:01.625922Z","iopub.execute_input":"2024-01-01T09:44:01.626695Z","iopub.status.idle":"2024-01-01T09:44:02.350843Z","shell.execute_reply.started":"2024-01-01T09:44:01.626662Z","shell.execute_reply":"2024-01-01T09:44:02.349927Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"(175621, 47)"},"metadata":{}}]},{"cell_type":"code","source":"decoder_inp=pad_sequences([arr[:-1] for arr in decoder],maxlen=max_decoder_sequence_len,padding=\"post\")\ndecoder_inp.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-01T09:44:02.351931Z","iopub.execute_input":"2024-01-01T09:44:02.352245Z","iopub.status.idle":"2024-01-01T09:44:03.418306Z","shell.execute_reply.started":"2024-01-01T09:44:02.352220Z","shell.execute_reply":"2024-01-01T09:44:03.417388Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"(175621, 57)"},"metadata":{}}]},{"cell_type":"code","source":"decoder_output=pad_sequences([arr[1:] for arr in decoder],maxlen=max_decoder_sequence_len,padding=\"post\")\ndecoder_output.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-01T09:44:03.419302Z","iopub.execute_input":"2024-01-01T09:44:03.419553Z","iopub.status.idle":"2024-01-01T09:44:04.516594Z","shell.execute_reply.started":"2024-01-01T09:44:03.419531Z","shell.execute_reply":"2024-01-01T09:44:04.515714Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"(175621, 57)"},"metadata":{}}]},{"cell_type":"code","source":"print([idx_2_txt_decoder[i] for i in decoder_output[0]])","metadata":{"execution":{"iopub.status.busy":"2024-01-01T09:44:04.517941Z","iopub.execute_input":"2024-01-01T09:44:04.518234Z","iopub.status.idle":"2024-01-01T09:44:04.523189Z","shell.execute_reply.started":"2024-01-01T09:44:04.518209Z","shell.execute_reply":"2024-01-01T09:44:04.522315Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"['salut!', 'end', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n","output_type":"stream"}]},{"cell_type":"code","source":"print([idx_2_txt_encoder[i] for i in encoder_seq[0]])","metadata":{"execution":{"iopub.status.busy":"2024-01-01T09:44:04.524305Z","iopub.execute_input":"2024-01-01T09:44:04.524570Z","iopub.status.idle":"2024-01-01T09:44:04.535822Z","shell.execute_reply.started":"2024-01-01T09:44:04.524547Z","shell.execute_reply":"2024-01-01T09:44:04.535003Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"['hi', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n","output_type":"stream"}]},{"cell_type":"markdown","source":" # **LSTM**","metadata":{}},{"cell_type":"code","source":"# encoder model\nencoder_input=Input(shape=(None,),name=\"encoder_input_layer\")\nencoder_embedding=Embedding(num_encoder_tokens,300,input_length=max_encoder_sequence_len,name=\"encoder_embedding_layer\")(encoder_input)\nencoder_lstm=LSTM(256,activation=\"tanh\",return_sequences=True,return_state=True,name=\"encoder_lstm_1_layer\")(encoder_embedding)\nencoder_lstm2=LSTM(256,activation=\"tanh\",return_state=True,name=\"encoder_lstm_2_layer\")(encoder_lstm)\n_,state_h,state_c=encoder_lstm2\nencoder_states=[state_h,state_c]","metadata":{"execution":{"iopub.status.busy":"2023-12-14T20:02:03.074515Z","iopub.execute_input":"2023-12-14T20:02:03.074830Z","iopub.status.idle":"2023-12-14T20:02:07.766347Z","shell.execute_reply.started":"2023-12-14T20:02:03.074806Z","shell.execute_reply":"2023-12-14T20:02:07.765578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# decoder model\ndecoder_input=Input(shape=(None,),name=\"decoder_input_layer\")\ndecoder_embedding=Embedding(num_decoder_tokens,300,input_length=max_decoder_sequence_len,name=\"decoder_embedding_layer\")(decoder_input)\ndecoder_lstm=LSTM(256,activation=\"tanh\",return_state=True,return_sequences=True,name=\"decoder_lstm_layer\")\ndecoder_outputs,_,_=decoder_lstm(decoder_embedding,initial_state=encoder_states)\ndecoder_dense=Dense(num_decoder_tokens+1,activation=\"softmax\",name=\"deocer_final_layer\")\noutputs=decoder_dense(decoder_outputs)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T20:02:07.770506Z","iopub.execute_input":"2023-12-14T20:02:07.770807Z","iopub.status.idle":"2023-12-14T20:02:08.075893Z","shell.execute_reply.started":"2023-12-14T20:02:07.770782Z","shell.execute_reply":"2023-12-14T20:02:08.074838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=Model([encoder_input,decoder_input],outputs)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-12-14T20:02:08.076961Z","iopub.execute_input":"2023-12-14T20:02:08.077262Z","iopub.status.idle":"2023-12-14T20:02:08.121527Z","shell.execute_reply.started":"2023-12-14T20:02:08.077236Z","shell.execute_reply":"2023-12-14T20:02:08.120668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder_seq.shape,decoder_inp.shape,decoder_output.shape","metadata":{"execution":{"iopub.status.busy":"2023-12-14T20:02:08.122549Z","iopub.execute_input":"2023-12-14T20:02:08.122823Z","iopub.status.idle":"2023-12-14T20:02:08.129232Z","shell.execute_reply.started":"2023-12-14T20:02:08.122799Z","shell.execute_reply":"2023-12-14T20:02:08.128254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmodel.compile(optimizer='rmsprop', loss=tf.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])\ncallback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\nhistory=model.fit(\n    [encoder_seq,decoder_inp],\n    decoder_output,\n    epochs=10,\n    batch_size=450,\n    # callbacks=[callback]\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T20:02:08.130625Z","iopub.execute_input":"2023-12-14T20:02:08.130966Z","iopub.status.idle":"2023-12-15T01:49:37.376663Z","shell.execute_reply.started":"2023-12-14T20:02:08.130936Z","shell.execute_reply":"2023-12-15T01:49:37.375730Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(\"/kaggle/working/Translate_Eng_FR.h5\")","metadata":{"execution":{"iopub.status.busy":"2023-12-15T01:50:33.279365Z","iopub.execute_input":"2023-12-15T01:50:33.280204Z","iopub.status.idle":"2023-12-15T01:50:33.637387Z","shell.execute_reply.started":"2023-12-15T01:50:33.280170Z","shell.execute_reply":"2023-12-15T01:50:33.636285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save_weights(\"/kaggle/working/model_NMT\")","metadata":{"execution":{"iopub.status.busy":"2023-12-15T01:50:57.611684Z","iopub.execute_input":"2023-12-15T01:50:57.612191Z","iopub.status.idle":"2023-12-15T01:50:58.047310Z","shell.execute_reply.started":"2023-12-15T01:50:57.612156Z","shell.execute_reply":"2023-12-15T01:50:58.046486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **GRU**","metadata":{}},{"cell_type":"code","source":"# Encoder model\nencoder_input = Input(shape=(None,), name=\"encoder_input_layer\")\nencoder_embedding = Embedding(num_encoder_tokens, 300, input_length=max_encoder_sequence_len, name=\"encoder_embedding_layer\")(encoder_input)\nencoder_gru = GRU(256, activation=\"tanh\", return_sequences=True, return_state=True, name=\"encoder_gru_1_layer\")(encoder_embedding)\n_, state_h = encoder_gru\nencoder_states = [state_h]  # Only one state for GRU\n","metadata":{"execution":{"iopub.status.busy":"2024-01-01T09:45:43.157324Z","iopub.execute_input":"2024-01-01T09:45:43.158144Z","iopub.status.idle":"2024-01-01T09:45:49.425263Z","shell.execute_reply.started":"2024-01-01T09:45:43.158113Z","shell.execute_reply":"2024-01-01T09:45:49.424507Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# Decoder model\ndecoder_input = Input(shape=(None,), name=\"decoder_in\\\nput_layer\")\ndecoder_embedding = Embedding(num_decoder_tokens, 300, input_length=max_decoder_sequence_len, name=\"decoder_embedding_layer\")(decoder_input)\ndecoder_gru = GRU(256, activation=\"tanh\", return_state=True, return_sequences=True, name=\"decoder_gru_layer\")\ndecoder_outputs, _ = decoder_gru(decoder_embedding, initial_state=encoder_states)\ndecoder_dense = Dense(num_decoder_tokens + 1, activation=\"softmax\", name=\"decoder_final_layer\")\noutputs = decoder_dense(decoder_outputs)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-01T09:45:53.448639Z","iopub.execute_input":"2024-01-01T09:45:53.449420Z","iopub.status.idle":"2024-01-01T09:45:53.699484Z","shell.execute_reply.started":"2024-01-01T09:45:53.449388Z","shell.execute_reply":"2024-01-01T09:45:53.698726Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# Build and compile the model\nmodel = Model([encoder_input, decoder_input], outputs)\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2024-01-01T09:45:58.158579Z","iopub.execute_input":"2024-01-01T09:45:58.158922Z","iopub.status.idle":"2024-01-01T09:45:58.197206Z","shell.execute_reply.started":"2024-01-01T09:45:58.158894Z","shell.execute_reply":"2024-01-01T09:45:58.196391Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n encoder_input_layer (Input  [(None, None)]               0         []                            \n Layer)                                                                                           \n                                                                                                  \n decoder_input_layer (Input  [(None, None)]               0         []                            \n Layer)                                                                                           \n                                                                                                  \n encoder_embedding_layer (E  (None, None, 300)            4171200   ['encoder_input_layer[0][0]'] \n mbedding)                                                                                        \n                                                                                                  \n decoder_embedding_layer (E  (None, None, 300)            8082600   ['decoder_input_layer[0][0]'] \n mbedding)                                                                                        \n                                                                                                  \n encoder_gru_1_layer (GRU)   [(None, None, 256),          428544    ['encoder_embedding_layer[0][0\n                              (None, 256)]                          ]']                           \n                                                                                                  \n decoder_gru_layer (GRU)     [(None, None, 256),          428544    ['decoder_embedding_layer[0][0\n                              (None, 256)]                          ]',                           \n                                                                     'encoder_gru_1_layer[0][1]'] \n                                                                                                  \n decoder_final_layer (Dense  (None, None, 26943)          6924351   ['decoder_gru_layer[0][0]']   \n )                                                                                                \n                                                                                                  \n==================================================================================================\nTotal params: 20035239 (76.43 MB)\nTrainable params: 20035239 (76.43 MB)\nNon-trainable params: 0 (0.00 Byte)\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"loss = tf.losses.SparseCategoricalCrossentropy()\nmodel.compile(optimizer='rmsprop', loss=loss, metrics=['accuracy'])\ncallback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n\n# Assuming you have data (encoder_seq, decoder_inp, decoder_output)\nhistory = model.fit(\n    [encoder_seq, decoder_inp],\n    decoder_output,\n    epochs=10,\n    batch_size=400,\n    # callbacks=[callback]\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-01T09:46:02.440244Z","iopub.execute_input":"2024-01-01T09:46:02.440603Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/10\n440/440 [==============================] - 256s 558ms/step - loss: 1.1249 - accuracy: 0.8738\nEpoch 2/10\n440/440 [==============================] - 247s 562ms/step - loss: 0.8035 - accuracy: 0.8842\nEpoch 3/10\n440/440 [==============================] - 247s 562ms/step - loss: 0.7758 - accuracy: 0.8856\nEpoch 4/10\n440/440 [==============================] - 247s 560ms/step - loss: 0.7570 - accuracy: 0.8871\nEpoch 5/10\n440/440 [==============================] - 246s 559ms/step - loss: 0.7412 - accuracy: 0.8884\nEpoch 6/10\n224/440 [==============>...............] - ETA: 2:00 - loss: 0.7316 - accuracy: 0.8893","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}